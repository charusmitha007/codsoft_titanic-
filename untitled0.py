# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z61adzQDHLjwAXNsler4IyJgjDlBY1HI
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

train_data = pd.read_csv('/content/Titanic-Dataset.csv')
data_test = pd.read_csv('/content/Titanic-Dataset.csv')
train_data.head()

train_data.info()
print('-'*40)
data_test.info()

fig = plt.figure(figsize=(8,8))
train_data['Survived'].value_counts().plot.pie(autopct = '%1.2f%%')

train_data['Embarked'][train_data['Embarked'].isnull()]
train_data['Embarked'][train_data['Embarked'].isnull()] = train_data['Embarked'].dropna().mode().values

train_data['Cabin'] = train_data['Cabin'].fillna('U0')

from sklearn.ensemble import RandomForestRegressor

age_df = train_data[['Age','Survived','Fare', 'Parch', 'SibSp', 'Pclass']]
age_df_notnull = age_df.loc[(train_data['Age'].notnull())]
age_df_isnull = age_df.loc[(train_data['Age'].isnull())]
X = age_df_notnull.values[:,1:]
Y = age_df_notnull.values[:,0]
# use RandomForestRegression to train data
RFR = RandomForestRegressor(n_estimators=1000,n_jobs=-1)
RFR.fit(X,Y)
predictAges = RFR.predict(age_df_isnull.values[:,1:])
train_data.loc[train_data['Age'].isnull(), ['Age']]= predictAges

train_data.info()

train_data.groupby(['Sex','Survived'])['Survived'].count()

survived_by_sex = train_data[['Sex','Survived']].groupby('Sex').mean()
type(survived_by_sex)
survived_by_sex.plot.bar()

train_data.groupby(['Pclass','Survived'])['Pclass'].count()

train_data[['Pclass','Survived']].groupby(['Pclass']).mean().plot.bar()

train_data.groupby(['Sex', 'Pclass', 'Survived'])['Survived'].count()

train_data[['Sex','Pclass','Survived']].groupby(['Pclass','Sex']).mean().plot.bar()

plt.figure(figsize=(12,5))
plt.subplot(121)
train_data['Age'].hist(bins=70)

plt.subplot(122)
train_data.boxplot(column='Age', showfliers=False)

facet = sns.FacetGrid(train_data,hue='Survived',aspect=4)
facet.map(sns.kdeplot, 'Age', shade=True)
facet.set(xlim=(0, train_data['Age'].max()))
facet.add_legend()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from google.colab import files
uploaded = files.upload()
train_data = pd.read_csv('/content/Titanic-Dataset.csv')

# Display the first few rows of the training data
train_data.head()

# Check for missing values
train_data.isnull().sum()

# Handle missing values
train_data['Age'].fillna(train_data['Age'].median(), inplace=True)
train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)
train_data.drop(columns=['Cabin', 'Ticket'], inplace=True)

# Convert categorical variables into dummy/indicator variables
train_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked'], drop_first=True)

# Define features and target variable
X = train_data.drop(columns=['Survived', 'Name', 'PassengerId'])
y = train_data['Survived']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the feature variables
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize and train the logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Classification report
print(classification_report(y_test, y_pred))

def check_survival(model, scaler, passenger_data):
    """
    Predicts survival of a given passenger.

    :param model: Trained logistic regression model
    :param scaler: Scaler used to standardize the data
    :param passenger_data: Dictionary containing passenger data
    :return: Survival prediction (0 or 1)
    """
    # Convert the passenger data into a DataFrame
    passenger_df = pd.DataFrame([passenger_data])

    # Handle missing values in the input data
    passenger_df['Age'].fillna(train_data['Age'].median(), inplace=True)
    passenger_df['Fare'].fillna(train_data['Fare'].median(), inplace=True)

    # Convert categorical variables into dummy/indicator variables
    passenger_df = pd.get_dummies(passenger_df, columns=['Sex', 'Embarked'], drop_first=True)

    # Align the passenger data with the training data columns
    passenger_df = passenger_df.reindex(columns=X.columns, fill_value=0)

    # Standardize the passenger data
    passenger_scaled = scaler.transform(passenger_df)

    # Make prediction
    prediction = model.predict(passenger_scaled)

    return prediction[0]

# Example passenger data
new_passenger = {
    'Pclass': 3,
    'Name': 'John Doe',
    'Sex': 'male',
    'Age': 25,
    'SibSp': 0,
    'Parch': 0,
    'Fare': 7.25,
    'Embarked': 'S'
}

survived = check_survival(model, scaler, new_passenger)
print(f'Predicted Survival: {"Yes" if survived == 1 else "No"}')

# Example passenger data 2
new_passenger = {
    'Pclass': 4,
    'Name': 'John Doe',
    'Sex': 'male',
    'Age': 66,
    'SibSp': 0,
    'Parch': 0,
    'Fare': 8.25,
    'Embarked': 'S'
}

survived = check_survival(model, scaler, new_passenger)
print(f'Predicted Survival: {"Yes" if survived == 1 else "No"}')

from google.colab import drive
drive.mount('/content/drive')